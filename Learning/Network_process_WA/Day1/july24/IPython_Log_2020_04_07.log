
from paramiko import SSHClient, AutoAddPolicy
def ssh_connect(host, username, password):
    from paramiko import SSHClient, AutoAddPolicy
    client = SSHClient()
    client.load_system_host_keys()
    client.set_missing_host_key_policy(AutoAddPolicy())
    client.connect(host, username=username, password=password)
    return client
    
ssh = ssh_connect("192.168.1.30", "testuser", "welcome")
ssh
sftp ssh.open_sftp()
sftp = ssh.open_sftp()
sftp
get_ipython().run_line_magic('pinfo', 'sftp.put')
sftp.getcwd()
sftp.chdir(".")
sftp.getcwd()

import xml.etree.ElementTree as et
et
get_ipython().run_line_magic('ls', '')
get_ipython().run_line_magic('load', 'xml/books.xml')
et.parse("xml/books.xml")
tree = et.parse("xml/books.xml")
print(tree)
tree.getroot()
root = tree.getroot()
root
root.tag
root.tag, root.attrib
root.tag, root.attrib, root.text
root.getchildren()
for book in catalog:
    print(boo)
for book in catalog:
    print(book)
for book in root:
    print(book)
root[0]
b1 = root[0]
b1
b1.tag
b1.tag, b1.attrib
b1.tag, b1.attrib, b1.text
for child in b1:
    print(child)
for child in b1:
    print(child.tag, "=", child.text)
root
root[-1]
root[-1].attrib["id"]
root[-1][0].text
root[:3]
for book in root:
    print(book[1].text)
# Builtin ElementTree library provides very basic XPath support
root.find("./book/author")
# Builtin ElementTree library provides very basic XPath support
root.find("./book/author").text
root.findall("./book/author")
root.iterfind("./book/author")
for author in root.iterfind("./book/author"):
    print(author.text)
root.findall(".//author") # Search for author amongst all descendant
root.findall("./*/title")
root.findall("./book[@country]")
root.findall("./book[title]")
root.findall("./book[author='O\'Brien, Tim']")
root.findall('''./book[author="O'Brien, Tim"]''')
root.findall('''./book[author="O'Brien, Tim"]/title''')
[ t.text for t in root.iterfind('''./book[author="O'Brien, Tim"]/title''') ]
[ t.text for t in root.iterfind("./book[price='5.95']/title") ]
[ t.text for t in root.iterfind("./book[price < '6.0']/title") ]
[ t.text for t in root.iterfind("./book[price < 6.0]/title") ]
for book in root:
    print(book.find("./title").text)
for book in root:
    if book.find("./price") == "5.95:"
        print(book.find("./title").text)
for book in root:
    if book.find("./price") == "5.95":
        print(book.find("./title").text)
for book in root:
    if book.find("./price").text == "5.95":
        print(book.find("./title").text)
for book in root:
    if float(book.find("./price").text) < 6.0:
        print(book.find("./title").text)
[ b.find("./title").text for b in root if float(b.find("./price").text) < 6.0]
import lxml.etree as et
import lxml.etree as et
et
tree1 = et.parse("xml/books.xml")
tree1
tree1[0]
tree1.getroot()
catalog = tree1.getroot()
catalog[0]
catalog[-1]
catalog[0].tag, catalog[0].text, catalog[0].attrib
catalog.findall("./book/title")
catalog.xpath("./book/title")
catalog.xpath("./book/title/text()")
[ b.find("./title").text for b in root if float(b.find("./price").text) < 6.0]
catalog.xpath("./book[price < 6.0]/title/text()")
et
et.parse("http://www.chandrashekar.info/contact")
get_ipython().run_line_magic('ls', 'xml/*.html')
import lxml.html as parser
doc = parser.parse("xml/github.html")
doc
doc.getroot()
html = doc.getroot()
html.xpath(".//a[@href]")
html.xpath(".//a[@href]/@href")
# pip install beautifulsoup4
from bs4 import BeautifulSoup
with open("xml/github.html") as infile:
    soup = BeautifulSoup(infile.read())
soup
with open("xml/github.html") as infile:
    soup = BeautifulSoup(infile.read())
type(soup)
soup.head
soup.head.link
soup.head.link["href"]
link = soup.head.link
while link:
    print(link["href"])
    link = link.next()
    
soup.select("a")
with open("xml/github.html") as infile:
    soup = BeautifulSoup(infile.read(), parser="lxml")
type(soup)
link = soup.head.link
    
link = soup.head.link
link
link = link.next
link
link = link.next
link
link = link.next
link
link = link.next
link
link = link.next
link
link = link.next
link
link = link.next
link
link = link.next
link
link = link.next
link
link = link.next
link
link = link.next
link
link = link.next
link
link = link.next
link
link = link.next
link
link = link.next
link
link = link.next
link
link = link.next
link
link = link.next
link
link = link.next
link
link = link.next
link
link = link.next
link
link = link.next
link
link = link.next
link
link = link.next
link
link = link.next
link
link = link.next
link
link = link.next
link
link = link.next
link
link = link.next
link
link = link.next
link
link = link.next
link
link = link.next
link
link = link.next
link
link = link.next
link
link = link.next
link
link = link.next
link
link = link.next
link
link = link.next
link
link = link.next
link
link = link.next
link
link = link.next
link
link = link.next
link
link = link.next
link
link = link.next
link
link = link.next
link
link = link.next
link
html
get_ipython().run_line_magic('pip', 'install cssselect')
from lxml.cssselect import CSSSelector
sel = CSSSelector("a")
sel
sel(html)
import parsel
from parsel import Selector
get_ipython().run_line_magic('pinfo', 'Selector')
with open("xml/github.html") as infile:
    selector = Selector(infile.read())
selector
selector.css("a")
selector.xpath(".//a")
selector.xpath(".//a").extract_first()
e = selector.xpath(".//a").extract_first()
e
e = selector.xpath(".//a")[0]
e
e.extract()
e.text()
e.text
e.xpath
e.xpath()
e.getall()
import http.client
from http.client import HTTPConnection
get_ipython().run_line_magic('pinfo', 'HTTPConnection')
http_conn = HTTPConnection("www.python.org", 80)
http_conn
get_ipython().run_line_magic('pinfo', 'http_conn.connect')
http_conn.connect()
get_ipython().run_line_magic('pinfo', 'http_conn.request')
r = http_conn.request("GET", "/")
r
r = http_conn.request("GET", "/")
r
r = http_conn.getresponse()
r
r.code
r.headers
r.headers.items()
r.read()
from urllib.request import urlopen
r = urlopen("http://www.python.org/")
r
r.code
r.read()
get_ipython().run_line_magic('pip', 'install requests2')
r = requests.get("http://www.python.org/")
r
import requests
r = requests.get("http://www.python.org/")
r
r.ok
r.status_code
r.headers
r.header["Content-Type"]
r.headers["Content-Type"]
r.header["CONTENT-type"]
r.headers["CONTENT-type"]
r.content
r.text
r.cookies
r = requests.get("http://www.cisco.com/")
r
r.cookies
r = requests.get("http://www.google.com/")
r
r.cookies
r.cookies.keys()
r.cookies.values()
r = requests.get("http://localhost:3000/posts")
r
r = requests.get("http://localhost:3000/pdfgfgosts")
r
r = requests.get("http://localhost:3000/posts")
r
r.ok
r.headers
r.text
r.json()
endpoint = "http://localhost:3000/posts"
r = requests.post(endpoint, 
                  json={"title": "april 7th", "author": "Chandrashekar"})
r
requests.get(endpoint)
requests.get(endpoint).json()
requests.get("http://localhost:3000/9")
requests.get("http://localhost:3000/posts/9")
r = requests.get("http://localhost:3000/posts/9")
if r.ok:
    print(r.json())
r = requests.get("http://localhost:3000/posts/Chandrashekar")
r
requests.put("http://localhost:3000/posts/9", json={"title": "april 6th"})
requests.get(http://localhost:3000/posts/9).json()
requests.get("http://localhost:3000/posts/9").json()
requests.put("http://localhost:3000/posts/9", 
             json={"title": "april 6th", "author": "Chandrashekar",
                   "description": "a simple resource object"})
requests.get("http://localhost:3000/posts/9").json()
requests.patch("http://localhost:3000/posts/9", 
             json={"title": "april 7th"})
requests.get("http://localhost:3000/posts/9").json()
requests.delete("http://localhost:3000/posts/9")
API_KEY = "932c152d6ff8d185bfdd9d2a5f8e33e4"
url = "http://api.openweathermap.org/data/2.5/weather",

qs = {"q": "Bengaluru", "appid": API_KEY, "units": "metric"}
qs

r = requests.get(url, params=qs)
r
url = "https://api.openweathermap.org/data/2.5/weather",

qs = {"q": "Bengaluru", "appid": API_KEY, "units": "metric"}
qs

r = requests.get(url, params=qs)
r
url = "http://api.openweathermap.org/data/2.5/weather",

qs = {"q": "Bengaluru", "appid": API_KEY, "units": "metric"}
qs

r = requests.get(url, params=qs)
r
url = "http://api.openweathermap.org/data/2.5/weather"

qs = {"q": "Bengaluru", "appid": API_KEY, "units": "metric"}
qs

r = requests.get(url, params=qs)
r
r.headers["content-type"]
r.json()
r = requests.get(url, params=qs, headers={"Accept": "application/xml"})
r
r.headers["content-type"]
qs = {"q": "Bengaluru", 
      "appid": API_KEY, 
      "units": "metric",
      "mode": "xml"}
r = requests.get(url, params=qs, headers={"Accept": "application/xml"})
r
r.headers["content-type"]
r.text
et
et.fromstring(r.text)
et.fromstring(r.content)
c = et.fromstring(r.content)
c = et.fromstring(r.content)
c
r.text
c.xpath(".//temperature")
c.xpath(".//temperature/@min")
get_ipython().run_line_magic('pip', 'install mechanicalsoup')
from mechanicalsoup import StatefulBrowser
get_ipython().set_next_input('browser = StatefulBrowser');get_ipython().run_line_magic('pinfo', 'StatefulBrowser')
browser = StatefulBrowser()
browser
browser.open("http://www.python.org/")
browser.absolute_url
browser.absolute_url()
browser.url()
browser.get_url()
get_ipython().run_line_magic('pinfo', 'browser.open')
browser.links
browser.links()
get_ipython().run_line_magic('pinfo', 'browser.get_link')
get_ipython().run_line_magic('pinfo', 'browser.find_link')
browser.find_link(href="/community/logos/")
browser.find_link(text="Arts")
l = browser.find_link(text="Arts")
browser.follow_link(l)
browser.get_url()
browser.get_current_form()
browser.open("http://www.python.org/")
browser.select_form()
f = browser.select_form()
f
f.q
f.form
f["q"] = "Guido Van Rossum"
browser.submit(f)
browser.submit()
browser.submit(f)
browser.submit_selected()
browser.get_url()
home_page = "http://testing.chandrashekar.info/"

login_url = "http://testing.chandrashekar.info/wp-login.php"
username = testuser
password = 'w3lc0me'

dashboard_url = "http://testing.chandrashekar.info/wp-admin/"

add_new_posts_url = "http://testing.chandrashekar.info/wp-admin/post-new.php"
home_page = "http://testing.chandrashekar.info/"

login_url = "http://testing.chandrashekar.info/wp-login.php"
username = "testuser"
password = 'w3lc0me'

dashboard_url = "http://testing.chandrashekar.info/wp-admin/"

add_new_posts_url = "http://testing.chandrashekar.info/wp-admin/post-new.php"
from mechanicalsoup import StatefulBrowser
browser = StatefulBrowser()
browser.open(login_url)
browser.get_url()
browser.open(login_url)
assert browser.get_url() == login_url
loginform = browser.select_form("#loginform")
loginform.print_summary()
browser["log"] = username
browser["pwd"] = password
browser.submit_selected()
browser.get_url()
browser.find_link("Add New")
browser.find_link(text="Add New")
browser.follow_link(text="Add New")
browser.get_url()
post_form = browser.select_form(action="post.php")
post_form.print_summary()
post_form = browser.select_form("action='post.php'")
post_form.print_summary()
post_form = browser.select_form("form[action='post.php']")
post_form.print_summary()
#post_form = browser.select_form("form[action='post.php']")
post_form = browser.select_form("#post")
post_form.print_summary()
browser["post_title"] = "A new blog post by Chandrashekar - April 7th"
browser["content"] = "This is a test blog by Chandrashekar..."
get_ipython().run_line_magic('pinfo', 'browser.submit_selected')
browser.submit_selected("input#publish")
browser.submit_selected("input[name='publish']")
browser.submit_selected("[name='publish']")
get_ipython().run_line_magic('pinfo', 'browser.get')
get_ipython().run_line_magic('pinfo', 'browser.session')
browser.request
get_ipython().run_line_magic('pinfo', 'browser.request')
browser.text
browser.get_current_page()
page = browser.get_current_page()
page.select("input#publish")
page.select("input#publish")[0]
inp = page.select("input#publish")[0]
inp.parents
list(inp.parents)
get_ipython().run_line_magic('pinfo', 'inp.find_parent')
inp.find_parent("form")
inp = page.select("input#publish")[0]
inp
browser.submit_selected(inp)
get_ipython().run_line_magic('pinfo', 'browser.submit')
from mechanicalsoup import StatefulBrowser
browser = StatefulBrowser()
browser.open(login_url)
assert browser.get_url() == login_url
loginform = browser.select_form("#loginform")
loginform.print_summary()
browser["log"] = username
browser["pwd"] = password
browser.submit_selected()
browser.get_url()
browser.follow_link(text="Add New")
browser.get_url()
#post_form = browser.select_form("form[action='post.php']")
post_form = browser.select_form("#post")
post_form.print_summary()
browser["post_title"] = "A new blog post by Chandrashekar - April 7th"
browser["content"] = "This is a test blog by Chandrashekar..."
post_form["post_title"] = "A new blog post by Chandrashekar - April 7th"
post_form["content"] = "This is a test blog by Chandrashekar..."
publish_btn = browser.get_current_page().select("input#publish")[0]
browser.submit_selected(publish_btn)
page = browser.get_current_page()
inp = page.select("input#publish")
get_ipython().run_line_magic('pip', 'install requests_html')
from requests_html import HTMLSession
sess = HTMLSession()
r = sess.get("https://finance.yahoo.com/quote/CSCO/options?p=CSCO")
r
r.text
r.html
r.html.links
r.html.absolute_links
r.html.form
r.html.xpath
r.html.xpath(".//span[@class='Trsdu(0.3s) Fw(b) Fz(36px) Mb(-4px) D(ib)']")
r.html.xpath(".//span[@class='Trsdu(0.3s) Fw(b) Fz(36px) Mb(-4px) D(ib)']/text()")
r.html.xpath(".//option")
r.html.render()
exit()
